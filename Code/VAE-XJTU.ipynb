{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Alonso Menéndez González"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code necessary to prepare the datasets and manage the model, comprising the First and Second step in the Fault Detection System. Specifically, this code was made for the XJTU-SY dataset, but with minor adjustments, it could be reused for any dataset.\n",
    "\n",
    "First, the dataset is loaded and the model is defined in a Class, which will be later extended to include the training loop. Afterwards, it is trained using the selected dataset's healthy samples, process monitorized by using wandb. Finally, after the model has finished learning from the healthy distributions, it is asked to predict the mean and variances of the whole dataset, which are saved for the next step in the Fault Detection System.\n",
    "\n",
    "**Please note:** This code was written as a Google Colab Notebook that uses Weights & Biases. Therefore, several changes must be made before executing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Imports and installations](#toc1_1_)    \n",
    "- [Dataset](#toc2_)    \n",
    "  - [Getting a sample](#toc2_1_)    \n",
    "- [Model Definition](#toc3_)    \n",
    "  - [Encoder](#toc3_1_)    \n",
    "    - [Test](#toc3_1_1_)    \n",
    "  - [Decoder](#toc3_2_)    \n",
    "    - [Test](#toc3_2_1_)    \n",
    "  - [LogLikelihood](#toc3_3_)    \n",
    "    - [Test](#toc3_3_1_)    \n",
    "  - [VAE class](#toc3_4_)    \n",
    "    - [Test](#toc3_4_1_)    \n",
    "  - [Training Loop](#toc3_5_)    \n",
    "- [Train Model](#toc4_)    \n",
    "- [Test model](#toc5_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Imports and installations](#toc0_)\n",
    "Packages, libraries and Wandb key setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "executionInfo": {
     "elapsed": 8317,
     "status": "error",
     "timestamp": 1717682411424,
     "user": {
      "displayName": "ALONSO MENENDEZ GONZALEZ",
      "userId": "00653166541482751966"
     },
     "user_tz": -120
    },
    "id": "mMK123e577YC",
    "outputId": "85f280a9-7b1d-4e09-ceee-610d1fb607f9"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qu8323C3dvlO"
   },
   "outputs": [],
   "source": [
    "!pip install wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OE1QXH3bcVnc"
   },
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFCFmkV8d419"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "from google.colab import userdata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jX_d0QT0dy_T"
   },
   "outputs": [],
   "source": [
    "wandb_key = userdata.get('wandb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login(key=wandb_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Dataset](#toc0_)\n",
    "Preparation of the CustomDataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2DUYSZ7AzWf"
   },
   "outputs": [],
   "source": [
    "# These are just the names of the experiments\n",
    "condition = \"40Hz10kN\" #\"37.5Hz11kN\" # \"40Hz10kN\"\n",
    "bearing = \"Bearing3_4\" #\"Bearing2_1\" #\"Bearing2_3\" \"Bearing3_1\" \"Bearing3_4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfZ7VBl0X-OY"
   },
   "outputs": [],
   "source": [
    "csv_directory = \"/content/drive/MyDrive/TFM/XJTU-SY_Bearing_Datasets/\" + condition +\"/\"+ bearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rcuxjxebFJmL"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, folder_path, partitions=1,top=300):\n",
    "      \"\"\"\n",
    "      folder_path: Path to the folder containing the dataset. Expects to find several csv files in it. \n",
    "      partitions: if each file is too big (memory limitations), consider increasing this number to split them into smaller chunks. Default 1.\n",
    "      top: number of files to consider as healthy (only get the top n files). Default 300.\n",
    "      \"\"\"\n",
    "      self.folder_path = folder_path\n",
    "      self.file_paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path)][:top]\n",
    "      self.partitions = partitions\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths) * self.partitions\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_index = index // self.partitions\n",
    "        part_index = index % self.partitions\n",
    "\n",
    "        file_path = self.file_paths[file_index]\n",
    "        df = pd.read_csv(file_path,sep=\",\")#, header=None)\n",
    "        chunks = np.array_split(df, self.partitions)\n",
    "        data = chunks[part_index]\n",
    "        tensor = torch.Tensor(data.values)\n",
    "        tensor = torch.flatten(tensor)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "azbp8zdsX-OZ"
   },
   "outputs": [],
   "source": [
    "dataset = CustomDataset(folder_path=csv_directory) # As top is 300, this is the \"training dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1717309735927,
     "user": {
      "displayName": "ALONSO MENENDEZ GONZALEZ",
      "userId": "00653166541482751966"
     },
     "user_tz": -120
    },
    "id": "RzGTu28aUSrI",
    "outputId": "9625b664-77e2-42da-9b75-0980f4a636de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset) # Should be the same as \"top\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUjvQJvuYxQp"
   },
   "outputs": [],
   "source": [
    "batch_size = 8 # Careful with big datasets and memory available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[Getting a sample](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zylyQJTxRrEJ"
   },
   "outputs": [],
   "source": [
    "train = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ZkesPYfTGBK"
   },
   "outputs": [],
   "source": [
    "i = next(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1717309742723,
     "user": {
      "displayName": "ALONSO MENENDEZ GONZALEZ",
      "userId": "00653166541482751966"
     },
     "user_tz": -120
    },
    "id": "Zhr7qVxVirU9",
    "outputId": "b29b8a7f-e336-4e33-ead6-af9d8d6b630f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 65536])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = i.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Model Definition](#toc0_)\n",
    "Contains all the necessary classes to build the VAE_extended class. Each section contains small tests that were used during development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_1_'></a>[Encoder](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, dimz, input_size):\n",
    "\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.dimz = dimz    #dimz is k, the dimension of the latent space\n",
    "\n",
    "        self.linear1 = nn.Linear(input_size, 3500)\n",
    "        self.linear2 = nn.Linear(3500, 700)\n",
    "        self.linear3 = nn.Linear(700, 200)\n",
    "        self.linear4 = nn.Linear(200,10)\n",
    "        self.linear5 = nn.Linear(10,dimz*2)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        z = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        z = self.relu(self.linear1(z))\n",
    "        z = self.relu(self.linear2(z))\n",
    "        z = self.relu(self.linear3(z))\n",
    "        z = self.relu(self.linear4(z))\n",
    "\n",
    "\n",
    "\n",
    "        z = self.linear5(z)\n",
    "\n",
    "        return z\n",
    "\n",
    "    def encode_and_sample(self,x,flag_sample=True):\n",
    "\n",
    "        # This methods compute both the posterior mean and variance\n",
    "        # Also we obtain a sample from the posterior using the\n",
    "        # reparameterization trick.\n",
    "\n",
    "        # We obtain the encoder projection using the forward method\n",
    "\n",
    "        z = self.forward(x)\n",
    "\n",
    "        # The mean is the first dimz components of the forward output\n",
    "\n",
    "        #mu = torch.clamp(z[:,:self.dimz], min=0.0) # Monotonic\n",
    "        mu = z[:,:self.dimz]\n",
    "\n",
    "        # We compute the variance from the last dimz components using a\n",
    "        # soft plus\n",
    "        var = self.softplus(0.5 * z[:, self.dimz:])\n",
    "\n",
    "        sample = None\n",
    "\n",
    "        if(flag_sample==True):\n",
    "\n",
    "            eps = torch.randn_like(var)\n",
    "\n",
    "            sample = mu + eps*(var**0.5)\n",
    "\n",
    "        return mu,var,sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_1_'></a>[Test](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wj3nL65LRObl"
   },
   "outputs": [],
   "source": [
    "#enc = encoder(dimz=2,input_size=input_size)\n",
    "#mu_z, var_z, sample = enc.encode_and_sample(x=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mu_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_2_'></a>[Decoder](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, dimz, output_size):\n",
    "\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.dimz = dimz    #dimz is k, the dimension of the latent space\n",
    "\n",
    "        self.linear1 = nn.Linear(dimz,10)\n",
    "        self.linear2 = nn.Linear(10,200)\n",
    "        self.linear3 = nn.Linear(200,700)\n",
    "        self.linear4 = nn.Linear(700,3500)\n",
    "        self.linear5 = nn.Linear(3500,output_size)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,z):\n",
    "\n",
    "        z = self.relu(self.linear1(z))\n",
    "        z = self.relu(self.linear2(z))\n",
    "        z = self.relu(self.linear3(z))\n",
    "        z = self.relu(self.linear4(z))\n",
    "        x = self.tanh(self.linear5(z))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def decode(self,z):\n",
    "\n",
    "        return self.forward(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_2_1_'></a>[Test](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KdhrjZdNTn4x"
   },
   "outputs": [],
   "source": [
    "#dec = decoder(dimz=2,output_size=input_size)\n",
    "#x_mean = dec.decode(mu_z).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eBMMR8i1UZsh"
   },
   "outputs": [],
   "source": [
    "#x_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_mean.reshape(batch_size,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_3_'></a>[LogLikelihood](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_Gaussian_LL(x,mu_x,var_x):\n",
    "\n",
    "    # x is a mini-batch of data. It has dimension [Batch,n_recordings,n_sensors]\n",
    "\n",
    "    # mu_x is a mini-batch of reconstructed images. It has dimension [Batch,n_recordings,n_sensors]\n",
    "\n",
    "    # var_x is a torch constant\n",
    "\n",
    "    D = x.shape[1] # Dimension of the image\n",
    "\n",
    "    x = x.reshape(-1, D)\n",
    "\n",
    "    mu_x = mu_x.reshape(-1, D)\n",
    "\n",
    "    var_x = torch.ones_like(mu_x) * var_x\n",
    "\n",
    "    # Constant term in the gaussian distribution\n",
    "    cnt = D * np.log(2 * np.pi) + torch.sum(torch.log(var_x), dim=-1)\n",
    "\n",
    "    # log-likelihood per datapoint\n",
    "\n",
    "    logp_data = -0.5 * (cnt + torch.sum((x - mu_x) * var_x ** -1 * (x - mu_x), dim=-1))\n",
    "\n",
    "    # Accumulated Gaussian log-likelihood for all datapoints in the batch\n",
    "    logp = torch.sum(logp_data)\n",
    "\n",
    "    return logp,logp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_3_1_'></a>[Test](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#var_x = 0.1\n",
    "#\n",
    "#logp,logp_data = eval_Gaussian_LL(i,x_mean,var_x)\n",
    "#\n",
    "#print(logp)\n",
    "#\n",
    "#plt.plot(np.arange(0,batch_size),logp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_4_'></a>[VAE class](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self,dimz,input_size,var_x=0.1):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.var_x = var_x\n",
    "\n",
    "        self.dimz = dimz\n",
    "        self.input_size = input_size\n",
    "\n",
    "        # We create an encoder network\n",
    "\n",
    "        self.encoder = encoder(self.dimz, self.input_size)\n",
    "\n",
    "        # We create a decoder network\n",
    "\n",
    "        self.decoder = decoder(self.dimz, self.input_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        # In the forward method, we return the mean and variance\n",
    "        # given by the encoder network and also the reconstruction mean\n",
    "        # given by the decoder network using a sample from the\n",
    "        # encoder's posterior distribution.\n",
    "\n",
    "        mu_z,var_z,sample_z = self.encoder.encode_and_sample(x=x)\n",
    "\n",
    "        # Decoder provides the mean of the reconstruction\n",
    "\n",
    "        mu_x = self.decoder.decode(sample_z)\n",
    "\n",
    "        return mu_x,mu_z,var_z\n",
    "\n",
    "    # Reconstruction + KL divergence losses summed over all elements and batch\n",
    "\n",
    "    def loss_function(self, x, mu_x, mu_z, var_z):\n",
    "\n",
    "        # We evaluate the loglikelihood in the batch using the function provided above\n",
    "\n",
    "        logp,_ = eval_Gaussian_LL(x, mu_x, torch.tensor(0.1))\n",
    "\n",
    "        # KL divergence between q(z) and N()\n",
    "        # see Appendix B from VAE paper:\n",
    "        # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "        # https://arxiv.org/abs/1312.6114\n",
    "\n",
    "        KLz = -0.5 * torch.sum(1 + torch.log(var_z) - mu_z.pow(2) - var_z)\n",
    "\n",
    "        # To maximize ELBO we minimize loss (-ELBO)\n",
    "        return -logp + KLz, -logp, KLz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_4_1_'></a>[Test](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZ1Nfna86kc5"
   },
   "outputs": [],
   "source": [
    "#my_vae = VAE(dimz=2,input_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(my_vae.loss_function(i,x_mean,mu_z,var_z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_5_'></a>[Training Loop](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_extended(VAE):\n",
    "\n",
    "    def __init__(self,name,notes,\n",
    "                 dimz=2,  input_size=3, var_x=0.1,lr=1e-3,epochs=20,\n",
    "                 save_folder='/content/drive/MyDrive/TFM/models/',restore=False,\n",
    "                 ):\n",
    "\n",
    "        super().__init__(dimz,input_size=input_size,var_x=var_x)\n",
    "\n",
    "        self.lr = lr\n",
    "        self.optim = optim.Adam(self.parameters(), self.lr)\n",
    "        self.epochs = epochs\n",
    "\n",
    "        self.save_folder = save_folder\n",
    "        self.name = name\n",
    "\n",
    "        if(restore==True):\n",
    "            state_dict = torch.load(self.save_folder+self.name+'.pth')\n",
    "            self.load_state_dict(state_dict)\n",
    "\n",
    "        self.loss_during_training = []\n",
    "        self.reconstruc_during_training = []\n",
    "        self.KL_during_training = []\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(self.device)\n",
    "\n",
    "\n",
    "\n",
    "        wandb.init(\n",
    "          project=\"TFM\",\n",
    "          entity=\"healthcare-ai\",\n",
    "          name=name,\n",
    "          notes=notes,\n",
    "          config={\n",
    "            \"epochs\": epochs,\n",
    "            \"layer_size\": [input_size, 4000, 1000, 200, 50, dimz],\n",
    "            \"lr\": lr,\n",
    "            \"var_x\": var_x,\n",
    "            })\n",
    "\n",
    "    def trainloop(self,trainloader):\n",
    "\n",
    "        nims = len(trainloader.dataset)\n",
    "\n",
    "        self.train()\n",
    "\n",
    "        for e in range(int(self.epochs)):\n",
    "\n",
    "            train_loss = 0\n",
    "            train_rec = 0\n",
    "            train_kl_l = 0\n",
    "\n",
    "            idx_batch = 0\n",
    "\n",
    "            for items in trainloader:\n",
    "\n",
    "                items = items.to(self.device)\n",
    "\n",
    "                self.optim.zero_grad()\n",
    "\n",
    "                mu_x, mu_z, var_z = self.forward(items)\n",
    "\n",
    "                loss, rec, kl_l = self.loss_function(items,mu_x, mu_z, var_z)\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                train_rec += rec.item()\n",
    "                train_kl_l += kl_l.item()\n",
    "\n",
    "                self.optim.step()\n",
    "\n",
    "                if (idx_batch % (len(trainloader)//20) == 0):\n",
    "\n",
    "                  print(f'Training: {idx_batch}/{len(trainloader)}')\n",
    "\n",
    "                if(idx_batch%10==0):\n",
    "\n",
    "                    torch.save(self.state_dict(), self.save_folder + self.name +'.pth')\n",
    "                    #print(f'Train Batch: {idx_batch}')\n",
    "\n",
    "                idx_batch += 1\n",
    "\n",
    "\n",
    "            self.loss_during_training.append(train_loss/len(trainloader))\n",
    "            self.reconstruc_during_training.append(train_rec/len(trainloader))\n",
    "            self.KL_during_training.append(train_kl_l/len(trainloader))\n",
    "\n",
    "            metrics = {\"train/train_loss\": train_loss/len(trainloader),\n",
    "                       \"train/train_reconstruction\": train_rec/len(trainloader),\n",
    "                       \"train/train_kl_loss\": train_kl_l/len(trainloader),\n",
    "                       \"train/epoch\": e,\n",
    "                       }\n",
    "\n",
    "            wandb.log(metrics)\n",
    "\n",
    "            if(e%1==0):\n",
    "\n",
    "                torch.save(self.state_dict(), self.save_folder + self.name +'.pth')\n",
    "                print('Train Epoch: {} \\tLoss: {:.6f}'.format(e,self.loss_during_training[-1]))\n",
    "\n",
    "\n",
    "    def sample(self,num_imgs):\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            eps = torch.randn([num_imgs,self.dimz]).to(self.device)\n",
    "\n",
    "            x_sample = self.decoder.decode(eps)\n",
    "\n",
    "            return x_sample.to(\"cpu\").detach()\n",
    "\n",
    "    def encode_and_sample_loop(self, dataloader, flag_sample=True):\n",
    "      \"\"\"\n",
    "\n",
    "\n",
    "      parameters:\n",
    "        dataloader: of a dataset. Careful with batch size.\n",
    "        flag_sample: if true, a sample with mu and var will be computed.\n",
    "\n",
    "\n",
    "      For each of the elements of dataloader, encode and obtain the following:\n",
    "        mu_x: mean of the element, of size (batch_size, dimz)\n",
    "        var_x: variance, same size\n",
    "        sample: using the previous values, adquire a sample.\n",
    "      \"\"\"\n",
    "      for items in dataloader:\n",
    "        items = items.to(self.device)\n",
    "        mu_x, var_x, sample = self.encoder.encode_and_sample(x=items,flag_sample=flag_sample)\n",
    "\n",
    "        for row_index in range(mu_x.shape[0]):\n",
    "          mu = mu_x[row_index].tolist()\n",
    "          var = var_x[row_index].tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "          wandb.log({\"mu0\":mu[0],\n",
    "                     #\"mu1\":mu[1],\n",
    "                     #\"mu2\":mu[2],\n",
    "                     #\"mu3\":mu[3],\n",
    "                     #\"mu4\":mu[4],\n",
    "                     \"var0\":var[0],\n",
    "                     #\"var1\":var[1],\n",
    "                     #\"var2\":var[2],\n",
    "                     #\"var3\":var[3],\n",
    "                     #\"var4\":var[4],\n",
    "                     })\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Train Model](#toc0_)\n",
    "Code for training the model. First the class is initialized and the trainloop is executed afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 39109,
     "status": "ok",
     "timestamp": 1717309782149,
     "user": {
      "displayName": "ALONSO MENENDEZ GONZALEZ",
      "userId": "00653166541482751966"
     },
     "user_tz": -120
    },
    "id": "5v5fhytO-H8y",
    "outputId": "f756cdf9-b014-4c5d-ae34-b1bcff408550"
   },
   "outputs": [],
   "source": [
    "my_vae_scratch = VAE_extended(name=\"VAE-XJTU-3-4-First\",\n",
    "                              notes=\"First attempt, using 300 healthy, same arquitecture as with IMS. 2nd part\",\n",
    "                              dimz=1, epochs=20, lr=1e-5,\n",
    "                              input_size=input_size, restore=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6492543,
     "status": "ok",
     "timestamp": 1717321926857,
     "user": {
      "displayName": "ALONSO MENENDEZ GONZALEZ",
      "userId": "00653166541482751966"
     },
     "user_tz": -120
    },
    "id": "xo-tVhLVWV21",
    "outputId": "93628321-2d0e-40ba-e17f-f62c113ac515"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 0/38\n",
      "Training: 1/38\n",
      "Training: 2/38\n",
      "Training: 3/38\n",
      "Training: 4/38\n",
      "Training: 5/38\n",
      "Training: 6/38\n",
      "Training: 7/38\n",
      "Training: 8/38\n",
      "Training: 9/38\n",
      "Training: 10/38\n",
      "Training: 11/38\n",
      "Training: 12/38\n",
      "Training: 13/38\n",
      "Training: 14/38\n",
      "Training: 15/38\n",
      "Training: 16/38\n",
      "Training: 17/38\n",
      "Training: 18/38\n",
      "Training: 19/38\n",
      "Training: 20/38\n",
      "Training: 21/38\n",
      "Training: 22/38\n",
      "Training: 23/38\n",
      "Training: 24/38\n",
      "Training: 25/38\n",
      "Training: 26/38\n",
      "Training: 27/38\n",
      "Training: 28/38\n",
      "Training: 29/38\n",
      "Training: 30/38\n",
      "Training: 31/38\n",
      "Training: 32/38\n",
      "Training: 33/38\n",
      "Training: 34/38\n",
      "Training: 35/38\n",
      "Training: 36/38\n",
      "Training: 37/38\n",
      "Train Epoch: 0 \tLoss: 587760.733553\n",
      "Training: 0/38\n",
      "Training: 1/38\n",
      "Training: 2/38\n",
      "Training: 3/38\n",
      "Training: 4/38\n",
      "Training: 5/38\n",
      "Training: 6/38\n",
      "Training: 7/38\n",
      "Training: 8/38\n",
      "Training: 9/38\n",
      "Training: 10/38\n",
      "Training: 11/38\n",
      "Training: 12/38\n",
      "Training: 13/38\n",
      "Training: 14/38\n",
      "Training: 15/38\n",
      "Training: 16/38\n",
      "Training: 17/38\n",
      "Training: 18/38\n",
      "Training: 19/38\n",
      "Training: 20/38\n",
      "Training: 21/38\n",
      "Training: 22/38\n",
      "Training: 23/38\n",
      "Training: 24/38\n",
      "Training: 25/38\n",
      "Training: 26/38\n",
      "Training: 27/38\n",
      "Training: 28/38\n",
      "Training: 29/38\n",
      "Training: 30/38\n",
      "Training: 31/38\n",
      "Training: 32/38\n",
      "Training: 33/38\n",
      "Training: 34/38\n",
      "Training: 35/38\n",
      "Training: 36/38\n",
      "Training: 37/38\n",
      "Train Epoch: 1 \tLoss: 586772.416118\n",
      "Training: 0/38\n",
      "Training: 1/38\n",
      "Training: 2/38\n",
      "Training: 3/38\n",
      "Training: 4/38\n",
      "Training: 5/38\n",
      "Training: 6/38\n",
      "Training: 7/38\n",
      "Training: 8/38\n",
      "Training: 9/38\n",
      "Training: 10/38\n",
      "Training: 11/38\n",
      "Training: 12/38\n",
      "Training: 13/38\n",
      "Training: 14/38\n",
      "Training: 15/38\n",
      "Training: 16/38\n",
      "Training: 17/38\n",
      "Training: 18/38\n",
      "Training: 19/38\n",
      "Training: 20/38\n",
      "Training: 21/38\n",
      "Training: 22/38\n",
      "Training: 23/38\n",
      "Training: 24/38\n",
      "Training: 25/38\n",
      "Training: 26/38\n",
      "Training: 27/38\n",
      "Training: 28/38\n",
      "Training: 29/38\n",
      "Training: 30/38\n",
      "Training: 31/38\n",
      "Training: 32/38\n",
      "Training: 33/38\n",
      "Training: 34/38\n",
      "Training: 35/38\n",
      "Training: 36/38\n",
      "Training: 37/38\n",
      "Train Epoch: 2 \tLoss: 586268.186678\n",
      "Training: 0/38\n",
      "Training: 1/38\n",
      "Training: 2/38\n",
      "Training: 3/38\n",
      "Training: 4/38\n",
      "Training: 5/38\n",
      "Training: 6/38\n",
      "Training: 7/38\n",
      "Training: 8/38\n",
      "Training: 9/38\n",
      "Training: 10/38\n",
      "Training: 11/38\n",
      "Training: 12/38\n",
      "Training: 13/38\n",
      "Training: 14/38\n",
      "Training: 15/38\n",
      "Training: 16/38\n",
      "Training: 17/38\n",
      "Training: 18/38\n",
      "Training: 19/38\n",
      "Training: 20/38\n",
      "Training: 21/38\n",
      "Training: 22/38\n",
      "Training: 23/38\n",
      "Training: 24/38\n",
      "Training: 25/38\n",
      "Training: 26/38\n",
      "Training: 27/38\n",
      "Training: 28/38\n",
      "Training: 29/38\n",
      "Training: 30/38\n",
      "Training: 31/38\n",
      "Training: 32/38\n",
      "Training: 33/38\n",
      "Training: 34/38\n",
      "Training: 35/38\n",
      "Training: 36/38\n",
      "Training: 37/38\n",
      "Train Epoch: 3 \tLoss: 585898.387336\n",
      "Training: 0/38\n",
      "Training: 1/38\n",
      "Training: 2/38\n",
      "Training: 3/38\n",
      "Training: 4/38\n",
      "Training: 5/38\n",
      "Training: 6/38\n",
      "Training: 7/38\n",
      "Training: 8/38\n",
      "Training: 9/38\n",
      "Training: 10/38\n",
      "Training: 11/38\n",
      "Training: 12/38\n",
      "Training: 13/38\n",
      "Training: 14/38\n",
      "Training: 15/38\n",
      "Training: 16/38\n",
      "Training: 17/38\n",
      "Training: 18/38\n",
      "Training: 19/38\n",
      "Training: 20/38\n",
      "Training: 21/38\n",
      "Training: 22/38\n",
      "Training: 23/38\n",
      "Training: 24/38\n",
      "Training: 25/38\n",
      "Training: 26/38\n",
      "Training: 27/38\n",
      "Training: 28/38\n",
      "Training: 29/38\n",
      "Training: 30/38\n",
      "Training: 31/38\n",
      "Training: 32/38\n",
      "Training: 33/38\n",
      "Training: 34/38\n",
      "Training: 35/38\n",
      "Training: 36/38\n",
      "Training: 37/38\n",
      "Train Epoch: 4 \tLoss: 585536.684211\n",
      "Training: 0/38\n",
      "Training: 1/38\n",
      "Training: 2/38\n",
      "Training: 3/38\n",
      "Training: 4/38\n",
      "Training: 5/38\n",
      "Training: 6/38\n",
      "Training: 7/38\n",
      "Training: 8/38\n",
      "Training: 9/38\n",
      "Training: 10/38\n",
      "Training: 11/38\n",
      "Training: 12/38\n",
      "Training: 13/38\n",
      "Training: 14/38\n",
      "Training: 15/38\n",
      "Training: 16/38\n",
      "Training: 17/38\n",
      "Training: 18/38\n",
      "Training: 19/38\n",
      "Training: 20/38\n",
      "Training: 21/38\n",
      "Training: 22/38\n",
      "Training: 23/38\n",
      "Training: 24/38\n",
      "Training: 25/38\n",
      "Training: 26/38\n",
      "Training: 27/38\n",
      "Training: 28/38\n",
      "Training: 29/38\n",
      "Training: 30/38\n",
      "Training: 31/38\n",
      "Training: 32/38\n",
      "Training: 33/38\n",
      "Training: 34/38\n",
      "Training: 35/38\n",
      "Training: 36/38\n",
      "Training: 37/38\n",
      "Train Epoch: 5 \tLoss: 585204.935855\n",
      "Training: 0/38\n",
      "Training: 1/38\n",
      "Training: 2/38\n",
      "Training: 3/38\n",
      "Training: 4/38\n",
      "Training: 5/38\n",
      "Training: 6/38\n",
      "Training: 7/38\n",
      "Training: 8/38\n",
      "Training: 9/38\n",
      "Training: 10/38\n",
      "Training: 11/38\n",
      "Training: 12/38\n",
      "Training: 13/38\n",
      "Training: 14/38\n",
      "Training: 15/38\n",
      "Training: 16/38\n",
      "Training: 17/38\n",
      "Training: 18/38\n",
      "Training: 19/38\n",
      "Training: 20/38\n",
      "Training: 21/38\n",
      "Training: 22/38\n",
      "Training: 23/38\n",
      "Training: 24/38\n",
      "Training: 25/38\n",
      "Training: 26/38\n",
      "Training: 27/38\n",
      "Training: 28/38\n",
      "Training: 29/38\n",
      "Training: 30/38\n",
      "Training: 31/38\n",
      "Training: 32/38\n",
      "Training: 33/38\n",
      "Training: 34/38\n",
      "Training: 35/38\n",
      "Training: 36/38\n",
      "Training: 37/38\n",
      "Train Epoch: 6 \tLoss: 584886.500822\n",
      "Training: 0/38\n",
      "Training: 1/38\n",
      "Training: 2/38\n",
      "Training: 3/38\n",
      "Training: 4/38\n",
      "Training: 5/38\n",
      "Training: 6/38\n",
      "Training: 7/38\n",
      "Training: 8/38\n",
      "Training: 9/38\n",
      "Training: 10/38\n",
      "Training: 11/38\n",
      "Training: 12/38\n",
      "Training: 13/38\n",
      "Training: 14/38\n",
      "Training: 15/38\n",
      "Training: 16/38\n",
      "Training: 17/38\n",
      "Training: 18/38\n",
      "Training: 19/38\n",
      "Training: 20/38\n",
      "Training: 21/38\n",
      "Training: 22/38\n",
      "Training: 23/38\n",
      "Training: 24/38\n",
      "Training: 25/38\n",
      "Training: 26/38\n",
      "Training: 27/38\n",
      "Training: 28/38\n",
      "Training: 29/38\n",
      "Training: 30/38\n",
      "Training: 31/38\n",
      "Training: 32/38\n",
      "Training: 33/38\n",
      "Training: 34/38\n",
      "Training: 35/38\n",
      "Training: 36/38\n",
      "Training: 37/38\n",
      "Train Epoch: 7 \tLoss: 584660.435855\n",
      "Training: 0/38\n",
      "Training: 1/38\n",
      "Training: 2/38\n",
      "Training: 3/38\n",
      "Training: 4/38\n",
      "Training: 5/38\n",
      "Training: 6/38\n",
      "Training: 7/38\n",
      "Training: 8/38\n",
      "Training: 9/38\n",
      "Training: 10/38\n",
      "Training: 11/38\n",
      "Training: 12/38\n",
      "Training: 13/38\n",
      "Training: 14/38\n",
      "Training: 15/38\n",
      "Training: 16/38\n",
      "Training: 17/38\n",
      "Training: 18/38\n",
      "Training: 19/38\n",
      "Training: 20/38\n",
      "Training: 21/38\n",
      "Training: 22/38\n",
      "Training: 23/38\n",
      "Training: 24/38\n",
      "Training: 25/38\n",
      "Training: 26/38\n",
      "Training: 27/38\n",
      "Training: 28/38\n",
      "Training: 29/38\n",
      "Training: 30/38\n",
      "Training: 31/38\n",
      "Training: 32/38\n",
      "Training: 33/38\n",
      "Training: 34/38\n",
      "Training: 35/38\n",
      "Training: 36/38\n",
      "Training: 37/38\n",
      "Train Epoch: 8 \tLoss: 584330.283717\n",
      "Training: 0/38\n",
      "Training: 1/38\n",
      "Training: 2/38\n",
      "Training: 3/38\n",
      "Training: 4/38\n",
      "Training: 5/38\n",
      "Training: 6/38\n",
      "Training: 7/38\n",
      "Training: 8/38\n",
      "Training: 9/38\n",
      "Training: 10/38\n",
      "Training: 11/38\n",
      "Training: 12/38\n",
      "Training: 13/38\n",
      "Training: 14/38\n",
      "Training: 15/38\n",
      "Training: 16/38\n",
      "Training: 17/38\n",
      "Training: 18/38\n",
      "Training: 19/38\n",
      "Training: 20/38\n",
      "Training: 21/38\n",
      "Training: 22/38\n",
      "Training: 23/38\n",
      "Training: 24/38\n",
      "Training: 25/38\n",
      "Training: 26/38\n",
      "Training: 27/38\n",
      "Training: 28/38\n",
      "Training: 29/38\n",
      "Training: 30/38\n",
      "Training: 31/38\n",
      "Training: 32/38\n",
      "Training: 33/38\n",
      "Training: 34/38\n",
      "Training: 35/38\n",
      "Training: 36/38\n",
      "Training: 37/38\n",
      "Train Epoch: 9 \tLoss: 584053.347862\n",
      "Training: 0/38\n",
      "Training: 1/38\n",
      "Training: 2/38\n",
      "Training: 3/38\n",
      "Training: 4/38\n",
      "Training: 5/38\n",
      "Training: 6/38\n",
      "Training: 7/38\n",
      "Training: 8/38\n",
      "Training: 9/38\n",
      "Training: 10/38\n",
      "Training: 11/38\n",
      "Training: 12/38\n",
      "Training: 13/38\n",
      "Training: 14/38\n",
      "Training: 15/38\n",
      "Training: 16/38\n",
      "Training: 17/38\n",
      "Training: 18/38\n",
      "Training: 19/38\n",
      "Training: 20/38\n",
      "Training: 21/38\n",
      "Training: 22/38\n",
      "Training: 23/38\n",
      "Training: 24/38\n",
      "Training: 25/38\n",
      "Training: 26/38\n",
      "Training: 27/38\n",
      "Training: 28/38\n",
      "Training: 29/38\n",
      "Training: 30/38\n",
      "Training: 31/38\n",
      "Training: 32/38\n",
      "Training: 33/38\n",
      "Training: 34/38\n",
      "Training: 35/38\n",
      "Training: 36/38\n",
      "Training: 37/38\n",
      "Train Epoch: 10 \tLoss: 583747.860197\n",
      "Training: 0/38\n",
      "Training: 1/38\n",
      "Training: 2/38\n",
      "Training: 3/38\n",
      "Training: 4/38\n",
      "Training: 5/38\n",
      "Training: 6/38\n",
      "Training: 7/38\n",
      "Training: 8/38\n",
      "Training: 9/38\n",
      "Training: 10/38\n",
      "Training: 11/38\n",
      "Training: 12/38\n",
      "Training: 13/38\n",
      "Training: 14/38\n",
      "Training: 15/38\n",
      "Training: 16/38\n",
      "Training: 17/38\n",
      "Training: 18/38\n",
      "Training: 19/38\n",
      "Training: 20/38\n",
      "Training: 21/38\n",
      "Training: 22/38\n",
      "Training: 23/38\n",
      "Training: 24/38\n",
      "Training: 25/38\n",
      "Training: 26/38\n",
      "Training: 27/38\n",
      "Training: 28/38\n",
      "Training: 29/38\n",
      "Training: 30/38\n",
      "Training: 31/38\n",
      "Training: 32/38\n",
      "Training: 33/38\n",
      "Training: 34/38\n",
      "Training: 35/38\n",
      "Training: 36/38\n",
      "Training: 37/38\n",
      "Train Epoch: 11 \tLoss: 583421.004934\n",
      "Training: 0/38\n",
      "Training: 1/38\n",
      "Training: 2/38\n",
      "Training: 3/38\n",
      "Training: 4/38\n",
      "Training: 5/38\n",
      "Training: 6/38\n",
      "Training: 7/38\n",
      "Training: 8/38\n",
      "Training: 9/38\n",
      "Training: 10/38\n",
      "Training: 11/38\n",
      "Training: 12/38\n",
      "Training: 13/38\n",
      "Training: 14/38\n",
      "Training: 15/38\n",
      "Training: 16/38\n",
      "Training: 17/38\n",
      "Training: 18/38\n",
      "Training: 19/38\n",
      "Training: 20/38\n",
      "Training: 21/38\n",
      "Training: 22/38\n",
      "Training: 23/38\n",
      "Training: 24/38\n",
      "Training: 25/38\n",
      "Training: 26/38\n",
      "Training: 27/38\n",
      "Training: 28/38\n",
      "Training: 29/38\n",
      "Training: 30/38\n",
      "Training: 31/38\n",
      "Training: 32/38\n",
      "Training: 33/38\n",
      "Training: 34/38\n",
      "Training: 35/38\n",
      "Training: 36/38\n",
      "Training: 37/38\n",
      "Train Epoch: 12 \tLoss: 583247.441612\n",
      "Training: 0/38\n",
      "Training: 1/38\n",
      "Training: 2/38\n",
      "Training: 3/38\n",
      "Training: 4/38\n",
      "Training: 5/38\n",
      "Training: 6/38\n",
      "Training: 7/38\n",
      "Training: 8/38\n",
      "Training: 9/38\n",
      "Training: 10/38\n",
      "Training: 11/38\n",
      "Training: 12/38\n",
      "Training: 13/38\n",
      "Training: 14/38\n",
      "Training: 15/38\n",
      "Training: 16/38\n",
      "Training: 17/38\n",
      "Training: 18/38\n",
      "Training: 19/38\n",
      "Training: 20/38\n",
      "Training: 21/38\n",
      "Training: 22/38\n",
      "Training: 23/38\n",
      "Training: 24/38\n",
      "Training: 25/38\n",
      "Training: 26/38\n",
      "Training: 27/38\n",
      "Training: 28/38\n",
      "Training: 29/38\n",
      "Training: 30/38\n",
      "Training: 31/38\n",
      "Training: 32/38\n",
      "Training: 33/38\n",
      "Training: 34/38\n",
      "Training: 35/38\n",
      "Training: 36/38\n",
      "Training: 37/38\n",
      "Train Epoch: 13 \tLoss: 582994.459704\n",
      "Training: 0/38\n",
      "Training: 1/38\n",
      "Training: 2/38\n",
      "Training: 3/38\n",
      "Training: 4/38\n",
      "Training: 5/38\n",
      "Training: 6/38\n",
      "Training: 7/38\n",
      "Training: 8/38\n",
      "Training: 9/38\n",
      "Training: 10/38\n",
      "Training: 11/38\n",
      "Training: 12/38\n",
      "Training: 13/38\n",
      "Training: 14/38\n",
      "Training: 15/38\n",
      "Training: 16/38\n",
      "Training: 17/38\n",
      "Training: 18/38\n",
      "Training: 19/38\n",
      "Training: 20/38\n",
      "Training: 21/38\n",
      "Training: 22/38\n",
      "Training: 23/38\n",
      "Training: 24/38\n",
      "Training: 25/38\n",
      "Training: 26/38\n",
      "Training: 27/38\n",
      "Training: 28/38\n",
      "Training: 29/38\n",
      "Training: 30/38\n",
      "Training: 31/38\n",
      "Training: 32/38\n",
      "Training: 33/38\n",
      "Training: 34/38\n",
      "Training: 35/38\n",
      "Training: 36/38\n",
      "Training: 37/38\n",
      "Train Epoch: 14 \tLoss: 582855.632401\n",
      "Training: 0/38\n",
      "Training: 1/38\n",
      "Training: 2/38\n",
      "Training: 3/38\n",
      "Training: 4/38\n",
      "Training: 5/38\n",
      "Training: 6/38\n",
      "Training: 7/38\n",
      "Training: 8/38\n",
      "Training: 9/38\n",
      "Training: 10/38\n",
      "Training: 11/38\n",
      "Training: 12/38\n",
      "Training: 13/38\n",
      "Training: 14/38\n",
      "Training: 15/38\n",
      "Training: 16/38\n",
      "Training: 17/38\n",
      "Training: 18/38\n",
      "Training: 19/38\n",
      "Training: 20/38\n",
      "Training: 21/38\n",
      "Training: 22/38\n",
      "Training: 23/38\n",
      "Training: 24/38\n",
      "Training: 25/38\n",
      "Training: 26/38\n",
      "Training: 27/38\n",
      "Training: 28/38\n",
      "Training: 29/38\n",
      "Training: 30/38\n",
      "Training: 31/38\n",
      "Training: 32/38\n",
      "Training: 33/38\n",
      "Training: 34/38\n",
      "Training: 35/38\n",
      "Training: 36/38\n",
      "Training: 37/38\n",
      "Train Epoch: 15 \tLoss: 582567.658717\n",
      "Training: 0/38\n",
      "Training: 1/38\n",
      "Training: 2/38\n",
      "Training: 3/38\n",
      "Training: 4/38\n",
      "Training: 5/38\n",
      "Training: 6/38\n",
      "Training: 7/38\n",
      "Training: 8/38\n",
      "Training: 9/38\n",
      "Training: 10/38\n",
      "Training: 11/38\n",
      "Training: 12/38\n",
      "Training: 13/38\n",
      "Training: 14/38\n",
      "Training: 15/38\n",
      "Training: 16/38\n",
      "Training: 17/38\n",
      "Training: 18/38\n",
      "Training: 19/38\n",
      "Training: 20/38\n",
      "Training: 21/38\n",
      "Training: 22/38\n",
      "Training: 23/38\n",
      "Training: 24/38\n",
      "Training: 25/38\n",
      "Training: 26/38\n",
      "Training: 27/38\n",
      "Training: 28/38\n",
      "Training: 29/38\n",
      "Training: 30/38\n",
      "Training: 31/38\n",
      "Training: 32/38\n",
      "Training: 33/38\n",
      "Training: 34/38\n",
      "Training: 35/38\n",
      "Training: 36/38\n",
      "Training: 37/38\n",
      "Train Epoch: 16 \tLoss: 582213.361020\n",
      "Training: 0/38\n",
      "Training: 1/38\n",
      "Training: 2/38\n",
      "Training: 3/38\n",
      "Training: 4/38\n",
      "Training: 5/38\n",
      "Training: 6/38\n",
      "Training: 7/38\n",
      "Training: 8/38\n",
      "Training: 9/38\n",
      "Training: 10/38\n",
      "Training: 11/38\n",
      "Training: 12/38\n",
      "Training: 13/38\n",
      "Training: 14/38\n",
      "Training: 15/38\n",
      "Training: 16/38\n",
      "Training: 17/38\n",
      "Training: 18/38\n",
      "Training: 19/38\n",
      "Training: 20/38\n",
      "Training: 21/38\n",
      "Training: 22/38\n",
      "Training: 23/38\n",
      "Training: 24/38\n",
      "Training: 25/38\n",
      "Training: 26/38\n",
      "Training: 27/38\n",
      "Training: 28/38\n",
      "Training: 29/38\n",
      "Training: 30/38\n",
      "Training: 31/38\n",
      "Training: 32/38\n",
      "Training: 33/38\n",
      "Training: 34/38\n",
      "Training: 35/38\n",
      "Training: 36/38\n",
      "Training: 37/38\n",
      "Train Epoch: 17 \tLoss: 581984.162829\n",
      "Training: 0/38\n",
      "Training: 1/38\n",
      "Training: 2/38\n",
      "Training: 3/38\n",
      "Training: 4/38\n",
      "Training: 5/38\n",
      "Training: 6/38\n",
      "Training: 7/38\n",
      "Training: 8/38\n",
      "Training: 9/38\n",
      "Training: 10/38\n",
      "Training: 11/38\n",
      "Training: 12/38\n",
      "Training: 13/38\n",
      "Training: 14/38\n",
      "Training: 15/38\n",
      "Training: 16/38\n",
      "Training: 17/38\n",
      "Training: 18/38\n",
      "Training: 19/38\n",
      "Training: 20/38\n",
      "Training: 21/38\n",
      "Training: 22/38\n",
      "Training: 23/38\n",
      "Training: 24/38\n",
      "Training: 25/38\n",
      "Training: 26/38\n",
      "Training: 27/38\n",
      "Training: 28/38\n",
      "Training: 29/38\n",
      "Training: 30/38\n",
      "Training: 31/38\n",
      "Training: 32/38\n",
      "Training: 33/38\n",
      "Training: 34/38\n",
      "Training: 35/38\n",
      "Training: 36/38\n",
      "Training: 37/38\n",
      "Train Epoch: 18 \tLoss: 581765.984375\n",
      "Training: 0/38\n",
      "Training: 1/38\n",
      "Training: 2/38\n",
      "Training: 3/38\n",
      "Training: 4/38\n",
      "Training: 5/38\n",
      "Training: 6/38\n",
      "Training: 7/38\n",
      "Training: 8/38\n",
      "Training: 9/38\n",
      "Training: 10/38\n",
      "Training: 11/38\n",
      "Training: 12/38\n",
      "Training: 13/38\n",
      "Training: 14/38\n",
      "Training: 15/38\n",
      "Training: 16/38\n",
      "Training: 17/38\n",
      "Training: 18/38\n",
      "Training: 19/38\n",
      "Training: 20/38\n",
      "Training: 21/38\n",
      "Training: 22/38\n",
      "Training: 23/38\n",
      "Training: 24/38\n",
      "Training: 25/38\n",
      "Training: 26/38\n",
      "Training: 27/38\n",
      "Training: 28/38\n",
      "Training: 29/38\n",
      "Training: 30/38\n",
      "Training: 31/38\n",
      "Training: 32/38\n",
      "Training: 33/38\n",
      "Training: 34/38\n",
      "Training: 35/38\n",
      "Training: 36/38\n",
      "Training: 37/38\n",
      "Train Epoch: 19 \tLoss: 581458.513980\n"
     ]
    }
   ],
   "source": [
    "my_vae_scratch.trainloop(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1030, -0.0200,  0.0240,  ..., -0.1880, -0.2860, -0.1070],\n",
      "         [-0.0680, -0.0680, -0.0150,  ..., -0.0070, -0.1760, -0.2590],\n",
      "         [-0.0590,  0.1290, -0.0630,  ..., -0.0390, -0.1270, -0.2120],\n",
      "         ...,\n",
      "         [-0.1440, -0.1490, -0.1590,  ..., -0.0880, -0.1050, -0.2250],\n",
      "         [-0.1540, -0.0780, -0.0610,  ..., -0.0930, -0.0490, -0.1710],\n",
      "         [-0.0950, -0.0320, -0.2100,  ..., -0.3520, -0.1610, -0.1200]]])\n"
     ]
    }
   ],
   "source": [
    "for i in train_dataloader:\n",
    "  print(i)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[Test model](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "gqcZL4UKjOJ8"
   },
   "outputs": [],
   "source": [
    "dataset = CustomDataset(folder_path=csv_directory, top=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1717321927155,
     "user": {
      "displayName": "ALONSO MENENDEZ GONZALEZ",
      "userId": "00653166541482751966"
     },
     "user_tz": -120
    },
    "id": "d9F50YV8cFpO",
    "outputId": "d1937717-858f-494a-f898-f42a901cf8df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1514"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "qHH6BMxar3nO"
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "liOEHNVEsmCk"
   },
   "outputs": [],
   "source": [
    "dataloader = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1717321927156,
     "user": {
      "displayName": "ALONSO MENENDEZ GONZALEZ",
      "userId": "00653166541482751966"
     },
     "user_tz": -120
    },
    "id": "lT7dNb_8kK3N",
    "outputId": "bdd2e356-b7f9-499c-8aa7-835f5c69122d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 60023,
     "status": "ok",
     "timestamp": 1717217736303,
     "user": {
      "displayName": "ALONSO MENENDEZ GONZALEZ",
      "userId": "00653166541482751966"
     },
     "user_tz": -120
    },
    "id": "IvEQ85JRp4Tq",
    "outputId": "bd32aff1-419a-4854-8fff-29d45e65d05c"
   },
   "outputs": [],
   "source": [
    "my_vae_scratch = VAE_extended(name=\"VAE-XJTU-2-3-First\",\n",
    "                              notes=\"Drawing histograms\",\n",
    "                              dimz=1, epochs=0, lr=1e-5,\n",
    "                              input_size=input_size, restore=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8jSDToe1vMrh"
   },
   "outputs": [],
   "source": [
    "# If the following block fails, uncomment this line and try again\n",
    "# my_vae_scratch.encode_and_sample_loop(dataloader=dataloader,flag_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w87q5hHgCp_7"
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns=[\"mu_x\",\"var_x\"])\n",
    "\n",
    "for items in dataloader:\n",
    "        items = items.to(my_vae_scratch.device)\n",
    "        mu_x, var_x, sample = my_vae_scratch.encoder.encode_and_sample(x=items)\n",
    "        df = pd.DataFrame({\n",
    "            'mu_x': sum(mu_x.tolist(), []),\n",
    "            'var_x': sum(var_x.tolist(), []),\n",
    "        })\n",
    "\n",
    "        res = pd.concat([res,df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1717255777927,
     "user": {
      "displayName": "ALONSO MENENDEZ GONZALEZ",
      "userId": "00653166541482751966"
     },
     "user_tz": -120
    },
    "id": "yLB8fN_hGoMn",
    "outputId": "8d64c457-8665-46c8-e035-7a81e9a71e4b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"res\",\n  \"rows\": 2537,\n  \"fields\": [\n    {\n      \"column\": \"mu_x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.966138694555969,\n        \"min\": -12.461873054504395,\n        \"max\": 14.024789810180664,\n        \"num_unique_values\": 2537,\n        \"samples\": [\n          -6.299714088439941,\n          -9.416402816772461,\n          -0.11678066104650497\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"var_x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007322469753664869,\n        \"min\": 6.160443710712116e-09,\n        \"max\": 0.061486344784498215,\n        \"num_unique_values\": 2537,\n        \"samples\": [\n          0.0021766950376331806,\n          0.00023712273105047643,\n          0.009320195764303207\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "res"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-faa8ac11-7219-4108-86df-36ce30995817\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mu_x</th>\n",
       "      <th>var_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.131987</td>\n",
       "      <td>0.001321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.529427</td>\n",
       "      <td>0.000942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.898650</td>\n",
       "      <td>0.000658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.259309</td>\n",
       "      <td>0.000408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.499679</td>\n",
       "      <td>0.001598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>1.411085</td>\n",
       "      <td>0.022051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2533</th>\n",
       "      <td>-0.290470</td>\n",
       "      <td>0.012026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>3.984034</td>\n",
       "      <td>0.008962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535</th>\n",
       "      <td>6.151705</td>\n",
       "      <td>0.002184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2536</th>\n",
       "      <td>-0.464617</td>\n",
       "      <td>0.009252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2537 rows × 2 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-faa8ac11-7219-4108-86df-36ce30995817')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-faa8ac11-7219-4108-86df-36ce30995817 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-faa8ac11-7219-4108-86df-36ce30995817');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-ced91f8f-8e46-42c2-b5b6-ff80555ceb8b\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ced91f8f-8e46-42c2-b5b6-ff80555ceb8b')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-ced91f8f-8e46-42c2-b5b6-ff80555ceb8b button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "          mu_x     var_x\n",
       "0     6.131987  0.001321\n",
       "1    -4.529427  0.000942\n",
       "2     6.898650  0.000658\n",
       "3     9.259309  0.000408\n",
       "4    -3.499679  0.001598\n",
       "...        ...       ...\n",
       "2532  1.411085  0.022051\n",
       "2533 -0.290470  0.012026\n",
       "2534  3.984034  0.008962\n",
       "2535  6.151705  0.002184\n",
       "2536 -0.464617  0.009252\n",
       "\n",
       "[2537 rows x 2 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "executionInfo": {
     "elapsed": 971,
     "status": "ok",
     "timestamp": 1717255778892,
     "user": {
      "displayName": "ALONSO MENENDEZ GONZALEZ",
      "userId": "00653166541482751966"
     },
     "user_tz": -120
    },
    "id": "szEFmmf2yHNM",
    "outputId": "1be0faa8-892d-4335-9542-ff21ea460672"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res.hist(bins=100, figsize=(14, 5))  # Adjust the number of bins and figure size as needed\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ibcJ3geUz1aW"
   },
   "outputs": [],
   "source": [
    "res.to_csv(\"/content/drive/MyDrive/TFM/MeanVars/XJTU-3-1-mean-var.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOBD4DVF622nt9qLP5FVayN",
   "collapsed_sections": [
    "r6dxVOGh8UVr",
    "stAObXaXX7Vg",
    "EjRU_OCMF4or",
    "tvJ0v5atXEv5",
    "7L72U_PIXGzv",
    "EjO480GrXI6-",
    "UMdHAbnN3uGf",
    "6ao6PY376jTA",
    "pUJBeIgs-Gb_"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
